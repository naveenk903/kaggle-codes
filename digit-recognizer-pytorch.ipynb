{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation and Exploration"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_categorical(y, num_classes=10):\n    \"\"\" 1-hot encodes a tensor \"\"\"\n    return np.eye(num_classes, dtype='uint8')[y]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, root):\n        super(MNISTDataset, self).__init__()\n        self.df = pd.read_csv(\"/kaggle/input/digit-recognizer/\" + root)\n        self.data = self.df.to_numpy()\n        self.x , self.y = self.data[:, 1:] / 255., self.data[:, 0]\n        self.x = torch.from_numpy(self.x.reshape((-1, 1, 28, 28))).float()\n        self.y = torch.from_numpy(to_categorical(self.y)).float()\n\n    def __getitem__(self, idx):\n        return self.x[idx, :], self.y[idx,:]\n    \n    def __len__(self):\n        return len(self.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VAL_SPLIT = 0.1\ntrain_dataset = MNISTDataset(\"train.csv\")\ntrain_dataset_len = len(train_dataset)\ntrain_size = int((1 - VAL_SPLIT)*train_dataset_len)\nval_size = int(0.1*train_dataset_len)\n\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\ntrain_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_data_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n\nprint(\"Train dataset size: %d\" % (len(train_dataset)))\nprint(\"Validation dataset size: %d\" % (len(val_dataset)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef show_image(im, label=None):\n    plt.imshow(im.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n    if label is not None:\n        plt.title(label)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for x, y in train_data_loader:\n#     show_image(x[0], np.argmax(y.tolist()))\n#     break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\n\ntransformA = A.Compose([\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5)\n#     A.RandomBrightnessContrast(p=0.5)\n])\n\ns = None\nfor x, y in train_data_loader:\n    s = transformA(image=np.array(x[0].tolist()))['image']\n    show_image(x[0], np.argmax(y.tolist()))\n    break\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flatten(torch.nn.Module):\n    def forward(self, x):\n        batch_size = x.shape[0]\n        return x.view(batch_size, -1)\n\nclass Print(nn.Module):\n    def forward(self, x):\n        print(x.size())\n        return x\n\nclass ConvNeuralNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvNeuralNet, self).__init__()\n        self.classifier = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=2),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 32, kernel_size=3, padding=2),\n            nn.MaxPool2d(kernel_size=(2, 2)),\n            nn.Dropout(0.2),\n            \n            nn.Conv2d(32, 128, kernel_size=3, padding=2),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(128, 128, kernel_size=3, padding=2),\n            nn.MaxPool2d(kernel_size=(2, 2)),\n            nn.Dropout(0.2),\n            \n            nn.Conv2d(128, 256, kernel_size=3),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size=(2, 2)),\n            nn.Dropout(0.2),\n            \n            nn.Flatten(),\n            #Print(),\n            nn.Linear(4096, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.3),\n\n            nn.Linear(128, 32),\n            nn.ReLU(),\n            nn.BatchNorm1d(32),\n            nn.Dropout(0.5),\n            \n            nn.Linear(32, num_classes),\n            nn.Softmax()\n        ) \n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        out = self.classifier(x)\n        return out\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ConvNeuralNet(10).cuda()\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 50\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nval_total_step = len(val_data_loader)\nval_loss_list = []\nval_acc_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_data_loader):\n        # Run the forward pass\n        labels = torch.max(labels, 1)[1].cuda()\n        outputs = model(images.cuda()).cuda()\n        loss = criterion(outputs, labels)\n        loss_list.append(loss.item())\n\n        # Backprop and perform Adam optimisation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Track the accuracy\n        total = labels.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        correct = (predicted == labels).sum().item()\n        acc_list.append(correct / total)\n\n        if (i + 1) % 1000 == 0:\n            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct * 100./ total)))\n    for i, (images, labels) in enumerate(val_data_loader):\n        # Run the forward pass\n        labels = torch.max(labels, 1)[1].cuda()\n        outputs = model(images.cuda()).cuda()\n        loss = criterion(outputs, labels)\n        val_loss_list.append(loss.item())\n\n        # Track the accuracy\n        total = labels.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        correct = (predicted == labels).sum().item()\n        val_acc_list.append(correct * 100./ total)\n\n    print('Val Loss: {:.4f}, Val Accuracy: {:.2f}% \\n\\n\\n'\n          .format(np.mean(val_loss_list), np.mean(val_acc_list)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}